<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<title>Welcome to team TIDYBOY homepage!</title>
<meta http-equiv="Content-Type" content="text/html; charset=ks_c_5601-1987" />
<link href="global.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="Container">
  <div id="Top">
	<img src="images/snu.png" width="50" height="50" class="logo" />
    <h1>Team TIDYBOY</h1>
    <h2>Biointelligence Lab, Seoul National University</h2>
  </div>
  
<div id="nav">
	<ul>
		<li><a href="index.html">Home</a></li>
		<li><a href="members.html">Members</a></li>
		<li><a href="demo.html">Robot Demo</a></li>
		<li><a href="softwares.html">Open-Source</a></li>
		<li class="last"><a href="publications.html">Publications</a></li>
	</ul>
  </div>
  
  <div id="MainText">
	
<table width="530" align="left" border="0" cellspacing="0" cellpadding="0">
<tbody><tr align="left" valign="top"><td>
	<!--//<h2><font color="#000099" face="Arial,Helvetica">Media/Press</font></h2>//-->



	<SPAN class="title"><h1>Selected Publications</h1></SPAN>

	<UL type="none">
		<LI><SPAN class="lv2"><b>Human Body Orientation Estimation using Convolutional Neural Network<a href="https://arxiv.org/abs/1609.01984">(link)</a></b></SPAN></LI>
		<UL type="square">

			<LI>Jinyoung Choi, Beom-Jin Lee,and Byoung-Tak Zhang</LI>
			<LI>published in IROS 2016 Assistance and Service Robotics in a Human Environment Workshop </LI>
			<LI>Abstract</LI>
			We propose an active viewpoint selecting method based on human body orientation with consideration of the robot's given environment. This makes the robot position itself in front of the person to observe one's behavior

		</UL></UL>

	<UL type="none">
		<LI><SPAN class="lv2"><b>Multimodal Residual Learning for Visual QA<a href="https://arxiv.org/abs/1606.01455">(link)</a></b></SPAN></LI>
		<UL type="square">

			<LI>Jin-Hwa Kim, Sang-Woo Lee, Dong-Hyun Kwak, Min-Oh Heo, Jeonghee Kim, Jung-Woo Ha, Byoung-Tak Zhang</LI>
			<LI>published in NIPS 2016</LI>
			<LI>Abstract</LI>
			We propose Cambot which can be instantiated in any platform including robots, desktops and tablet PCs, which have a camera and microphone, engaging natural environmental situations of visual conversation for human interactions.

		</UL></UL>
	<UL type="none">
		<LI><SPAN class="lv2"><b>Pororobot: A deep learning robot that plays video Q&A games<a href="https://bi.snu.ac.kr/Publications/Conferences/International/AAAI_FSS-AI_HRI_2015_KMKim.pdf">(link)</a></b></SPAN></LI>
		<UL type="square">

			<LI>Kyung-Min Kim, Changjun Nan, Jung-Woo Ha, Yujung Heo, and Byoung-Tak Zhang</LI>
			<LI>published in AAAI 2015 Fall Symposium on AI for Human-Robot Interaction (AI-HRI 2015), pp. 89-93, 2015.</LI>
			<LI>Abstract</LI>
			We proposed a memory model called the deep concept hierarchy (DCH) model that enables the progressive abstraction of concept knowledge in multiple levels. Moreover, by employing the model to a mobile robot, it can learn the cartoon video with the child and teach the child what has happened in the video

		</UL></UL>

	<UL type="none">
		<LI><SPAN class="lv2"><b>Childbot: A conversational assistant for child care<a href="https://bi.snu.ac.kr/Publications/Conferences/International/PACS2016_HJo.pdf">(link)</a></b></SPAN></LI>
		<UL type="square">

			<LI>Hwiyeol Jo, Woo-Young Kang, Dong-Sig Han, Byoung-Tak Zhang </LI>
			<LI>published in International Symposium on Perception, Action, and Cognitive Systems: Beyond AlphaGo (PACS 2016), pp.91-92, 2016.</LI>
			<LI>Abstract</LI>
			We propose a RNN Encoder-Decoder (seq2seq) model[Sequence to sequence] for Korean conversational robot (Konvbot). We collected about 10,000 dialogue pairs for this scenario from more than 30 people. With the data, we implemented the base conversational model, which is used for collecting more dialogues in real environments.
		</UL></UL>

	<UL type="none">
		<LI><SPAN class="lv2"><b>Schedulebot: A home robot learning and acting schedule adaptively via dynamic environments<a href="https://bi.snu.ac.kr/Publications/Conferences/International/PACS2016_CYLee.pdf">(link)</a></b></SPAN></LI>
		<UL type="square">

			<LI>Chung-Yeon Lee, Chaeeun Lee, and  Byoung-Tak Zhang</LI>
			<LI>published in International Symposium on Perception, Action, and Cognitive Systems: Beyond AlphaGo (PACS 2016), pp.69-70, 2016.</LI>
			<LI>Abstract</LI>
			A Robot needs to understand the environments and ongoing events to operate safely and efficiently in complex real situations such as private homes. To illustrate some of these problems, we built a pseudo-real home environment that family members and a robot can interact with each other based on the morning at home scenario. Predicted events, activities, and robot actions following the results are shown in the video.

		</UL></UL>


	<UL type="none">
		<LI><SPAN class="lv2"><b>Bayesian Deep Learning for Incremental Teaching a Home Robot<a href="">(link)</a></b></SPAN></LI>
		<UL type="square">

			<LI>Jiseob Kim, Seongho Son,and Byoung-Tak Zhang</LI>
			<LI>submitted in AAAI2017</LI>
			<LI>Abstract</LI>
			Humans are very good at learning new objects. If some objects are unusual or confusing, they ask other people and learn from the answer. We investigate how this scenario can be performed by robots. Specifically, we develop a robot that adapts to dynamically changing home environments for which it actively asks human and learns online. In our setting the robot adapts to the new environment by actively asking for a confusing object and updating its recognition model from the answer in an online manner.

		</UL></UL>

	<UL type="none">
		<LI><SPAN class="lv2"><b>Multi-focus Attention Network
for Efficient Deep Reinforcement Learning<a href="">(link)</a></b></SPAN></LI>
		<UL type="square">

			<LI>Jinyoung Choi, Beom-Jin Lee,and Byoung-Tak Zhang</LI>
			<LI>submitted in AAAI2017</LI>
			<LI>Abstract</LI>
			We propose the Multi-focus Attention Network (MANet) which mimics human ability to spatially abstract the low-level sensory input into multiple entities and attend to them simultaneously. Our model showed significantly improved performances in grid world navigatoin problem and multi-agent combat problem.

		</UL></UL>



	<SPAN class="title"><h1>Related Works</h1></SPAN>
	<UL type="none"><LI><SPAN class="lv2">International Journal Papers</SPAN></LI>
		<UL type="square">
			<LI>Whole-body balancing walk controller for position controlled humanoid robots, S.-J. Yi, B.-T. Zhang, D. W. Hong, and D. D. Lee, International Journal of Humanoid Robotics, 13(1):1550047, 2016.<a href="https://bi.snu.ac.kr/Publications/Journals/International/IJHR_SJYi2016.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Consensus analysis and modeling of visual aesthetic perception, T.-S. Park and B.-T. Zhang, IEEE Transactions on Affective Computing, 6(3):272-285, 2015.<a href="https://bi.snu.ac.kr/Publications/Journals/International/IEEE_TAC_2015_TSPark.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI><a href="https://bi.snu.ac.kr/Publications/Journals/International/IJHR_SJYi2016.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Team THOR's entry in the DARPA robotics challenge trials 2013, S.-J. Yi, S.G. McGill, L. Vadakedathu, Q. He, I. Ha, J. Han, H. Song, M. Rouleau, B.-T. Zhang, D. Hong, M. Yim, and D.D. Lee, Journal of Field Robotics, 32(3):315-335, 2015.<a href="https://bi.snu.ac.kr/Publications/Journals/International/JFR_2015_SJYi.pdf">(link)</a></LI>
		</UL>

		<UL type="square">
			<LI>Bayesian evolutionary hypergraph learning for predicting cancer clinical outcomes, S.-J Kim, J.-W. Ha, and B.-T. Zhang, Journal of Biomedical Informatics, 49:101-111, 2014.<a href="https://bi.snu.ac.kr/Publications/Journals/International/JBI_2014_SJKim.pdf">(link)</a></LI>
		</UL>


	</UL>
	<UL type="none"><LI><SPAN class="lv2">International Conference Papers</LI>
		<UL type="square">
			<LI>DeepSchema: Automatic schema acquisition from wearable sensor data in restaurant situations, E.-S. Kim, K.-W. On, and B.-T. Zhang, International Joint Conference on Artificial Intelligence (IJCAI 2016), pp. 834-840, 2016.<a href="https://bi.snu.ac.kr/Publications/Conferences/International/IJCAI2016_ESKim.pdf">(link)</a></LI>
		</UL>

		<UL type="square">
			<LI>Dual-memory deep learning architectures for lifelong learning of everyday human behaviors, S.-W. Lee, C.-Y. Lee, D. H. Kwak, J. Kim, J. Kim, and B.-T. Zhang, International Joint Conference on Artificial Intelligence (IJCAI 2016), pp. 1669-1675, 2016.<a href="https://bi.snu.ac.kr/Publications/Conferences/International/IJCAI2016_SLee.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Storybot: Story learning from cartoon videos via consecutive event embedding, M.-O. Heo, and B.-T. Zhang, 2016 International Symposium on Perception, Action, and Cognitive Systems: Beyond AlphaGo (PACS 2016), pp.87-88, 2016. <a href="https://bi.snu.ac.kr/Publications/Conferences/International/PACS2016_MOHeo.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Cafebot - A conversational cashier robot in cafes, C. Han, K.-W. On, E.-S. Kim, and B.-T. Zhang, 2016 International Symposium on Perception, Action, and Cognitive Systems: Beyond AlphaGo (PACS 2016), pp.83-84, 2016. <a href="https://bi.snu.ac.kr/Publications/Conferences/International/PACS2016_CHan.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Knowledgebot: Neuroknowledge based complimentary learning model for question answering systems, K.-W. On, E.-S. Kim, and B.-T. Zhang, 2016 International Symposium on Perception, Action, and Cognitive Systems: Beyond AlphaGo (PACS 2016), pp.81-82, 2016.<a href="https://bi.snu.ac.kr/Publications/Conferences/International/PACS2016_KWOn.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Pandabot: Multimodal story learning with dynamic memory construction, Y.-J. Heo, E.-S. Kim,K.-W. On, and B.-T. Zhang, 2016 International Symposium on Perception, Action, and Cognitive Systems: Beyond AlphaGo (PACS 2016), pp.79-80, 2016.<a href="https://bi.snu.ac.kr/Publications/Conferences/International/PACS2016_YJHeo.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Jibobot: A personal assistant robot with social motions, E.-S. Kim, J. Kim, D.-H. Kwak,K.-W. On, and B.-T. Zhang, 2016 International Symposium on Perception, Action, and Cognitive Systems: Beyond AlphaGo (PACS 2016), pp.77-78, 2016. <a href="https://bi.snu.ac.kr/Publications/Conferences/International/PACS2016_ESKim.pdf">(link)</a></LI></UL>
		<UL type="square">
			<LI>Glassbot: Personalized wearable agents learning from everyday human behaviors, S.-W. Lee, C.-Y. Lee, D.-H. Kwak, and B.-T. Zhang, 2016 International Symposium on Perception, Action, and Cognitive Systems: Beyond AlphaGo (PACS 2016), pp.75-76, 2016.<a href="https://bi.snu.ac.kr/Publications/Conferences/International/PACS2016_SLee.pdf">(link)</a></LI>
		</UL>

		<UL type="square">
			<LI>Aupair: A home robot for personal care, B.-J. Lee and B.-T. Zhang, 2016 International Symposium on Perception, Action, and Cognitive Systems: Beyond AlphaGo (PACS 2016), pp.67-68, 2016. <a href="https://bi.snu.ac.kr/Publications/Conferences/International/PACS2016_BJLee.pdf">(link)</a></LI>
		</UL>

		<UL type="square">
			<LI>Modeling situated conversations for a child-care robot using wearable devices, K.-W. On, E.-S. Kim, and B.-T. Zhang, AAAI 2015 Fall Symposium on AI for Human-Robot Interaction (AI-HRI 2015), pp. 103-106, 2015. <a href="https://bi.snu.ac.kr/Publications/Conferences/International/AAAI_FSS-AI_HRI_2015_KWOn.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Behavioral pattern modeling of human-human interaction for teaching restaurant service robots, E.-S. Kim, K.-O. On, and B.-T. Zhang, AAAI 2015 Fall Symposium on AI for Human-Robot Interaction (AI-HRI 2015), 2015.<a href="https://bi.snu.ac.kr/Publications/Conferences/International/AAAI_FSS-AI_HRI_2015_ESKim.pdf">(link)</a></LI>
		</UL>

		<UL type="square">
			<LI>Schedule Management System for Child-Care Home Robot, D.-H. Kwak and B.-T. Zhang, AAAI 2015 Fall Symposium on AI for Human-Robot Interaction (AI-HRI 2015), 2015. <a href="https://bi.snu.ac.kr/Publications/Conferences/International/AAAI_FSS-AI_HRI_2015_DHKwak.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Non-parametric Bayesian sum-product networks, S.-W. Lee, C. J. Watkins, B.-T. Zhang, ICML Workshop on Learning Tractable Probabilistic Models, 2014.<a href="https://bi.snu.ac.kr/Publications/Conferences/International/ICML2014_W_LTPM_SLee.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Predictive property of hidden representations in recurrent neural network language models, S. Yoon, S.-W. Lee, and B.-T. Zhang, 2014 NIPS workshop on Modern Machine Learning Methods and Natural Language Processing, 2014. <a href="https://bi.snu.ac.kr/Publications/Conferences/International/NIPS2014_MLNLP_Workshop_SYoon.pdf">(link)</a></LI>
		</UL>

		<UL type="square">
			<LI>Online learning of low dimensional strategies for high-level push recovery in bipedal humanoid robots, S.-J. Yi, B.-T. Zhang, D. Hong, and D. D. Lee, In Proceedings of IEEE International Conference on Robotics and Automation (ICRA 2013), pp. 1649-1655, 2013.<a href="https://bi.snu.ac.kr/Publications/Conferences/International/ICRA2013_SJYi.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Estimating multiple evoked emotions from videos, W.H. Choe, H.-S. Chun, J. Noh, S.-D. Lee,and B.-T. Zhang, In Proceedings of Annual Meeting of the Cognitive Science Society (CogSci 2013), pp. 2046-2051, 2013.<a href="https://bi.snu.ac.kr/Publications/Conferences/International/CogSci2013_WonheeChoi.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Enhancing human action recognition through spatio-temporal feature learning and semantic rules, K. Ramirez-Amaro, E.-S. Kim, J. Kim, B.-T. Zhang, M. Beetz and G. Cheng, In Proceedings of 2013 IEEE-RAS International Conference on Humanoid Robots (Humanoids 2013), 456-461, 2013.<a href="https://bi.snu.ac.kr/Publications/Conferences/International/Humanoids2013_ESKim_JKim.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Data driven SLAM for a mobile robot with short ranged navigation sensors, J. Lee, S.-H. Ji, and B.-T. Zhang, Proceedings of the 17th International Conference on Mechatronics Technology (ICMT 2013), pp. 377-379, 2013.<a href="https://bi.snu.ac.kr/Publications/Conferences/International/ICMT2013_JLee_1.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Active stabilization of a humanoid robot for impact motions with unknown reaction forces, S.-J. Yi, B.-T. Zhang, D. Hong, and D. D. Lee, In Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2012), pp. 4034-4039, 2012. <a href="https://bi.snu.ac.kr/Publications/Conferences/International/IROS2012-SJ_Yi.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Sparse population code models of word learning in concept drift, B.-T. Zhang, J.-W. Ha, and M. Kang, In Proceedings of Annual Meeting of the Cognitive Science Society (CogSci 2012), pp. 1221-1226, 2012.<a href="https://bi.snu.ac.kr/Publications/Conferences/International/CogSci2012_BTZhang.pdf">(link)</a></LI>
		</UL>




	</UL>
	<UL type="none"><LI><SPAN class="lv2">Books&Magazines</LI>
		<UL type="square">
			<LI>B.-T. Zhang and Y.-Y. Choi, Communication: Human, animals, and artificial Intelligence (Korean translation of "Menschen, Tiere und Max: Natuerliche Kommunikation und kuenstliche Intelligenz" by I. Wachsmuth, Springer, 2012), Seoul National University Press, 2014.</LI>
		</UL>
		<UL type="square">
			<LI>Humans and machines in the evolution of AI in Korea, B.-T. Zhang, AI Magazine, 37(2):108-112, 2016.<a href="https://bi.snu.ac.kr/Publications/Journals/International/AIMag_BTZhang2016.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Deep learning-based video analysis techniques, J. Kim, C.-J. Nan, and B.-T. Zhang, Communications of the Korean Institute of Information Scientists and Engineers, 33(9):21-31, 2015. <a href="https://bi.snu.ac.kr/Publications/Journals/Domestic/KIISEC33_9_JKim.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Deep hypernetwork models, B.-T. Zhang, Communications of the Korean Institute of Information Scientists and Engineers, 33(8):11-24, 2015.<a href="https://bi.snu.ac.kr/Publications/Journals/Domestic/KIISEC33_8_BTZhang.pdf">(link)</a></LI>
		</UL>




	</UL>
	<UL type="none"><LI><SPAN class="lv2">Korean Journal Papers</LI>
		<UL type="square">
			<LI>Event cognition-based daily activity prediction using wearable sensors, C.-Y. Lee, D. H. Kwak, B.-J. Lee,and B.-T. Zhang, Journal of KIISE, 43(7):781-785, 2016.<a href="https://bi.snu.ac.kr/Publications/Journals/Domestic/KIISE43_7_CYLee.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Social network analysis of TV drama via location knowledge-learned deep hypernetworks, C.-J. Nan, K.-M. Kim, and B.-T. Zhang, KIISE Transactions on Computing Practices, 22(11):619-624, 2016.<a href="https://bi.snu.ac.kr/Publications/Journals/Domestic/KIISE_TCP_22_11_CJNan.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Character-based subtitle generation by learning of multimodal concept hierarchy from cartoon videos, K.M. Kim, J.-W. Ha, B.-J. Lee,and B.-T. Zhang, Journal of KIISE, 42(4):451-458, 2015.<a href="https://bi.snu.ac.kr/Publications/Journals/Domestic/KIISE42_4_KMKim.pdf">(link)</a></LI>
		</UL>
		<UL type="square">
			<LI>Smartphone-user interactive based self developing place-time-activity coupled prediction method for daily routine planning system, B.-J. Lee, J. Kim, J.-H. Ryu, M.-O. Heo, J.-S. Kim, and B.-T. Zhang, KIISE Transactions on Computing Practices, 21(2):154-159, 2015.<a href="https://bi.snu.ac.kr/Publications/Journals/Domestic/KIISE_CPL_21_2_BJLee.pdf">(link)</a></LI>
		</UL>


	</UL>
	<UL type="none"><LI><SPAN class="lv2">Korean Conference Papers</LI>
		<UL type="square">
			<LI>Human activity as a sequence to sequence representation, Patrick M. Emaase, Beom-Jin Lee, Byoung-Tak Zhang, 2016 한국컴퓨터종합학술대회(KCC2016)논문집, pp. 868-870, 2016.06.  <a href="https://bi.snu.ac.kr/Publications/Conferences/Domestic/KCC2016_SHSon.pdf"></a></LI>
		</UL>
		<UL type="square">
			<LI>베이지안 신경망을 활용하는 온라인 이미지 인식을 통한 순차 추정, 손성호, 김지섭, 장병탁, 2016 한국컴퓨터종합학술대회(KCC2016)논문집, pp. 1033-1035, 2016.06.<a href="https://bi.snu.ac.kr/Publications/Conferences/Domestic/KCC2016_PEmaase.pdf"></a></LI>
		</UL>
		<UL type="square">
			<LI>ActMap: 가정로봇의 사용자 일상생활 활동기록을 통한 고차 인지 특징점 발견 방법, 이범진, 장병탁, In 2016 한국인지과학학회 연차학술대회, 2016.05. </LI>
		</UL>
		<UL type="square">
			<LI>Deep convolutional neural network을 이용한 2D 영상에서의 사람 자세, 행동 및 위치 통합 인식 시스템, 김지섭, 김은솔, 윤상웅, 정문식, 최현수, 장병탁, 2015 한국컴퓨터종합학술대회(KCC2015)논문집, pp. 846-848, 2015.06..<a href="https://bi.snu.ac.kr/Publications/Conferences/Domestic/KCC2015_JKim.pdf"></a></LI>

		</UL>



	</UL>



</td></tr></tbody></table>                                                                                                                


  </div>
  <div id="Footer">
    <p> Copyright 2023, Biointelligence Lab. Seoul National University</p>
  </div>
</div>
</html>

